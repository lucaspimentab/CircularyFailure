{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b37669e",
   "metadata": {},
   "source": [
    "# Sequence Models (GRU / LSTM / Transformer)\n",
    "\n",
    "This notebook trains sequence models on an HDF5 dataset from **any dataset** (MIMIC/eICU/NWICU or external).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f2bff",
   "metadata": {},
   "source": [
    "## 1) Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ad73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import tables\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401d88d",
   "metadata": {},
   "source": [
    "## 2) Paths & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can point to ANY HDF5 file here\n",
    "# Example:\n",
    "# H5_PATH = Path('outputs/mimic/preprocess/h5/dataset_mimic.h5')\n",
    "# H5_PATH = Path('outputs/eicu/preprocess/h5/dataset_eicu.h5')\n",
    "# H5_PATH = Path('outputs/nwicu/preprocess/h5/dataset_features.h5')\n",
    "H5_PATH = Path('outputs/mimic/preprocess/h5/dataset_mimic.h5')\n",
    "\n",
    "# Training options\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "MAX_SEQ_LEN = 96\n",
    "SEED = 43\n",
    "DEVICE = 'auto'  # 'auto', 'cpu', or 'cuda'\n",
    "\n",
    "# Output metrics\n",
    "OUTPUT_DIR = Path(os.environ.get('OUTPUT_DIR', 'outputs'))\n",
    "METRICS_CSV = OUTPUT_DIR / 'reports' / 'metrics_sequence_models.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbad598",
   "metadata": {},
   "source": [
    "## 3) Inspect HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52858487",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not H5_PATH.exists():\n",
    "    raise FileNotFoundError(f'HDF5 not found: {H5_PATH}')\n",
    "\n",
    "with tables.open_file(H5_PATH, mode='r') as h5:\n",
    "    print('HDF5:', H5_PATH)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        x = h5.root.data[split]\n",
    "        y = h5.root.labels[split]\n",
    "        print(f'{split}: data={x.shape}, labels={y.shape}')\n",
    "    if hasattr(h5.root, 'static'):\n",
    "        print('Static features available:', h5.root.static)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059dee4",
   "metadata": {},
   "source": [
    "## 4) Train Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d97e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCRIPT = Path('scripts') / 'modeling' / 'train_sequence_model.py'\n",
    "\n",
    "cmd = [\n",
    "    'python', str(TRAIN_SCRIPT),\n",
    "    '--h5', str(H5_PATH),\n",
    "    '--batch-size', str(BATCH_SIZE),\n",
    "    '--epochs', str(EPOCHS),\n",
    "    '--max-seq-len', str(MAX_SEQ_LEN),\n",
    "    '--seed', str(SEED),\n",
    "    '--device', DEVICE,\n",
    "    '--model', 'transformer',\n",
    "    '--metrics-csv', str(METRICS_CSV),\n",
    "]\n",
    "\n",
    "print('Running Transformer:')\n",
    "print(' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4b65e",
   "metadata": {},
   "source": [
    "## 5) Train GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e912db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCRIPT = Path('scripts') / 'modeling' / 'train_sequence_model.py'\n",
    "\n",
    "cmd = [\n",
    "    'python', str(TRAIN_SCRIPT),\n",
    "    '--h5', str(H5_PATH),\n",
    "    '--batch-size', str(BATCH_SIZE),\n",
    "    '--epochs', str(EPOCHS),\n",
    "    '--max-seq-len', str(MAX_SEQ_LEN),\n",
    "    '--seed', str(SEED),\n",
    "    '--device', DEVICE,\n",
    "    '--model', 'gru',\n",
    "    '--metrics-csv', str(METRICS_CSV),\n",
    "]\n",
    "\n",
    "print('Running GRU:')\n",
    "print(' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b73c5f",
   "metadata": {},
   "source": [
    "## 6) Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SCRIPT = Path('scripts') / 'modeling' / 'train_sequence_model.py'\n",
    "\n",
    "cmd = [\n",
    "    'python', str(TRAIN_SCRIPT),\n",
    "    '--h5', str(H5_PATH),\n",
    "    '--batch-size', str(BATCH_SIZE),\n",
    "    '--epochs', str(EPOCHS),\n",
    "    '--max-seq-len', str(MAX_SEQ_LEN),\n",
    "    '--seed', str(SEED),\n",
    "    '--device', DEVICE,\n",
    "    '--model', 'lstm',\n",
    "    '--metrics-csv', str(METRICS_CSV),\n",
    "]\n",
    "\n",
    "print('Running LSTM:')\n",
    "print(' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d4fa2",
   "metadata": {},
   "source": [
    "## 7) View Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1880d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if METRICS_CSV.exists():\n",
    "    df = pd.read_csv(METRICS_CSV)\n",
    "    df\n",
    "else:\n",
    "    print('Metrics file not found:', METRICS_CSV)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}